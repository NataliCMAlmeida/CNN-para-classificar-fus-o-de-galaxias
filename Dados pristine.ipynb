{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f8090bbb-719a-4f03-989b-12516904d3a1",
   "metadata": {},
   "source": [
    "Extração de imagens .npy e .FITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a3a56a-dcb2-45c7-a0c0-0fb3741485a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Salvando imagens e metadados: 100%|█| 15426/15426 [00:21<00:00, 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Definir os caminhos dos arquivos\n",
    "file_x = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\SimSim_SOURCE_X_Illustris2_pristine.npy\"\n",
    "file_y = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\SimSim_SOURCE_y_Illustris2_pristine.npy\"\n",
    "\n",
    "# Carregar os arquivos usando np.load\n",
    "data_x = np.load(file_x)\n",
    "data_y = np.load(file_y)\n",
    "\n",
    "# Diretório para as imagens\n",
    "image_dir = \"pristineSS\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Criar um dicionário para os metadados\n",
    "metadata = {}\n",
    "\n",
    "# Usar tqdm para a barra de progresso\n",
    "for i in tqdm(range(data_x.shape[0]), desc=\"Salvando imagens e metadados\"):\n",
    "    image = data_x[i]\n",
    "    label = data_y\n",
    "\n",
    "    # Normaliza os dados da imagem para o intervalo [0, 1]\n",
    "    if np.max(image) != np.min(image):\n",
    "        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    else:\n",
    "        # Handle the case where max and min are equal\n",
    "        image = np.zeros_like(image)\n",
    "\n",
    "    # Verifique se os dados são em escala de cinza e converta para RGB\n",
    "    if image.shape[0] == 1:\n",
    "        image = plt.cm.viridis(image)\n",
    "\n",
    "    # Reorganize a forma da imagem para (altura, largura, canais)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    # Salva a imagem como um arquivo PNG\n",
    "    filename = f\"imagem_{i}.png\"\n",
    "    filepath = os.path.join(image_dir, filename)\n",
    "    plt.imsave(filepath, image)\n",
    "\n",
    "    # Adiciona a imagem e o rótulo ao dicionário de metadados\n",
    "    metadata[f\"imagem_{i}\"] = {\"rótulo\": label, \"arquivo\": filename}\n",
    "\n",
    "# Save the data to an HDF5 file\n",
    "with h5py.File(\"pristineSS.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"data_x\", data=data_x)\n",
    "    f.create_dataset(\"data_y\", data=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3779e843-9219-41a2-bdc8-eaf819b26ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Salvando imagens e metadados: 100%|█| 6000/6000 [00:20<00:00, 287\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Definir os caminhos dos arquivos\n",
    "file_x = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\SimReal_SOURCE_X_Illustris0.npy\"\n",
    "file_y = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\SimReal_SOURCE_y_Illustris0.npy\"\n",
    "\n",
    "# Carregar os arquivos usando np.load\n",
    "data_x = np.load(file_x)\n",
    "data_y = np.load(file_y)\n",
    "\n",
    "# Diretório para as imagens\n",
    "image_dir = \"pristineSR\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# Criar um dicionário para os metadados\n",
    "metadata = {}\n",
    "\n",
    "# Usar tqdm para a barra de progresso\n",
    "for i in tqdm(range(data_x.shape[0]), desc=\"Salvando imagens e metadados\"):\n",
    "    image = data_x[i]\n",
    "    label = data_y[i]\n",
    "\n",
    "    # Normaliza os dados da imagem para o intervalo [0, 1]\n",
    "    image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "    # Verifique se os dados são em escala de cinza e converta para RGB\n",
    "    if image.shape[0] == 1:\n",
    "        image = plt.cm.viridis(image)\n",
    "\n",
    "    # Reorganize a forma da imagem para (altura, largura, canais)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    # Salva a imagem como um arquivo PNG\n",
    "    filename = f\"imagem_{i}.png\"\n",
    "    filepath = os.path.join(image_dir, filename)\n",
    "    plt.imsave(filepath, image)\n",
    "\n",
    "    # Adiciona a imagem e o rótulo ao dicionário de metadados\n",
    "    metadata[f\"imagem_{i}\"] = {\"rótulo\": label, \"arquivo\": filename}\n",
    "\n",
    "# Salva os metadados como um arquivo HDF5\n",
    "with h5py.File(\"pristineSR.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"data_x\", data=data_x)\n",
    "    f.create_dataset(\"data_y\", data=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8081a6bf-0934-4504-a365-c3bad83088ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Salvando imagens: 100%|█████████| 16/16 [00:00<00:00, 252.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# Caminho do arquivo FITS\n",
    "file_fits = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\hlsp_deepmerge_hst_acs-wfc3_illustris-z2_f814w-f160w_v1_sim-pristine.fits\"\n",
    "\n",
    "# Abrir o arquivo FITS\n",
    "hdulist = fits.open(file_fits)\n",
    "\n",
    "# Acessar o cabeçalho do primeiro HDU (hdu[0])\n",
    "header = hdulist[0].header\n",
    "\n",
    "# Definir a seed para garantir a mesma seleção de imagens\n",
    "# np.random.seed(206265)  # descomente para obter sempre a mesma seleção\n",
    "\n",
    "# Selecionar 16 imagens aleatórias\n",
    "example_ids = np.random.choice(hdulist[1].data.shape[0], 16)\n",
    "\n",
    "# Criar um dicionário para armazenar as imagens\n",
    "images_data = {}\n",
    "\n",
    "# Loop pelas imagens selecionadas aleatoriamente e plotar com rótulos\n",
    "for i in tqdm(range(len(example_ids)), desc=\"Salvando imagens\"):  # Adicionando a barra de progresso\n",
    "    # Pegar as imagens F814W (índice=0) e F160W (índice=1)\n",
    "    image_f814w = hdulist[0].data[example_ids[i], 0, :, :]\n",
    "    image_f160w = hdulist[0].data[example_ids[i], 1, :, :]\n",
    "\n",
    "    # Normalizar as imagens\n",
    "    norm_f814w = simple_norm(image_f814w, 'log', max_percent=99.75)\n",
    "    norm_f160w = simple_norm(image_f160w, 'log', max_percent=99.75)\n",
    "\n",
    "    # Adicionar as imagens e o rótulo ao dicionário\n",
    "    images_data[f\"imagem_{i}\"] = {\n",
    "        \"f814w\": image_f814w.tolist(),\n",
    "        \"f160w\": image_f160w.tolist(),\n",
    "        \"merger\": bool(hdulist[1].data[example_ids[i]][0])\n",
    "    }\n",
    "\n",
    "# Salvar as imagens em um arquivo HDF5\n",
    "with h5py.File(\"pristineFITS.hdf5\", \"w\") as f:\n",
    "    for i in range(len(example_ids)):\n",
    "        f.create_dataset(f\"imagem_{i}/f814w\", data=images_data[f\"imagem_{i}\"][\"f814w\"])\n",
    "        f.create_dataset(f\"imagem_{i}/f160w\", data=images_data[f\"imagem_{i}\"][\"f160w\"])\n",
    "        f.create_dataset(f\"imagem_{i}/merger\", data=images_data[f\"imagem_{i}\"][\"merger\"])\n",
    "\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef95859a-4dfc-4ac9-888d-a8f0e4c7f17f",
   "metadata": {},
   "source": [
    "Extração da tabela illustris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387d0d31-20e0-4952-8b2f-e3759f70ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       snap  subid  logmstar  cam  merger rfprob  asym_I    cc_I     g_I  \\\n",
      "0       103      0     12.20    0   False  0.103  0.2076  2.9771  0.5534   \n",
      "1       103      0     12.20    3   False   0.15  0.2082  3.6671  0.5881   \n",
      "2       103      0     12.20    1   False  0.132  0.2069  3.6939  0.6117   \n",
      "3       103      0     12.20    2   False  0.231  0.2195  3.2588  0.5904   \n",
      "4       103  19702     12.12    3   False   None     NaN     NaN     NaN   \n",
      "...     ...    ...       ...  ...     ...    ...     ...     ...     ...   \n",
      "71946    54  18603      9.83    2   False   None -0.0648  2.6204  0.4758   \n",
      "71947    54   8205      9.82    1   False   None  0.0134  2.4736  0.4804   \n",
      "71948    54   8205      9.82    3   False   None  0.0519  2.4502  0.4625   \n",
      "71949    54   8205      9.82    2   False   None  0.1353  2.1423  0.4737   \n",
      "71950    54   8205      9.82    0   False   None  0.1309  2.4773  0.4857   \n",
      "\n",
      "        m20_I  mprime_I  asym_H    cc_H     g_H   m20_H  mprime_H  t_lastmaj  \\\n",
      "0     -1.4073   -1.3047  0.1193  3.6158  0.5952 -1.9186   -1.5796    -2.6956   \n",
      "1     -1.5640   -1.1394  0.1433  3.8279  0.5921 -1.9774   -1.2196    -2.6956   \n",
      "2     -1.5015   -1.0887  0.1663  3.8399  0.5917 -1.8892   -1.2522    -2.6956   \n",
      "3     -1.5522   -1.3975  0.1482  3.8950  0.6085 -2.0038   -1.3152    -2.6956   \n",
      "4         NaN       NaN     NaN     NaN     NaN     NaN       NaN    -0.5016   \n",
      "...       ...       ...     ...     ...     ...     ...       ...        ...   \n",
      "71946 -1.2925   -0.3358 -0.1215  2.2644  0.4750 -1.4103   -0.5217    -1.0475   \n",
      "71947 -1.5007   -1.1829 -0.1366  2.4745  0.5023 -1.5417    0.2205    -0.3715   \n",
      "71948 -1.3560   -0.8130 -0.1186  2.5425  0.4749 -1.5294    0.2499    -0.3715   \n",
      "71949 -1.2310   -0.5579 -0.0662  2.2829  0.4540 -1.4985    0.2494    -0.3715   \n",
      "71950 -1.3748   -0.6035 -0.1294  2.4766  0.4684 -1.6014    0.2461    -0.3715   \n",
      "\n",
      "       t_lastmin  t_nextmaj  t_nextmin  \n",
      "0        -0.6481     4.4276    50.0000  \n",
      "1        -0.6481     4.4276    50.0000  \n",
      "2        -0.6481     4.4276    50.0000  \n",
      "3        -0.6481     4.4276    50.0000  \n",
      "4        -1.4423    50.0000    50.0000  \n",
      "...          ...        ...        ...  \n",
      "71946   -50.0000    10.5717    50.0000  \n",
      "71947    -0.5883     0.2776     0.6182  \n",
      "71948    -0.5883     0.2776     0.6182  \n",
      "71949    -0.5883     0.2776     0.6182  \n",
      "71950    -0.5883     0.2776     0.6182  \n",
      "\n",
      "[71951 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Importing Illustris catalog\n",
    "catalog = pd.DataFrame(np.genfromtxt(r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\illustris_morphs_rf.txt\", dtype=None, encoding='utf-8'))\n",
    "catalog.columns = ['snap', 'subid', 'logmstar', 'cam', 'merger', 'rfprob', 'asym_I', 'cc_I', 'g_I', 'm20_I', 'mprime_I', 'asym_H', 'cc_H', 'g_H', 'm20_H', 'mprime_H', 't_lastmaj', 't_lastmin', 't_nextmaj', 't_nextmin']\n",
    "\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9efa0c1e-0625-4ca0-956f-2ce548b7fac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       snap  subid  logmstar  cam  merger rfprob  asym_I    cc_I     g_I  \\\n",
      "0       103      0     12.20    0   False  0.103  0.2076  2.9771  0.5534   \n",
      "1       103      0     12.20    3   False   0.15  0.2082  3.6671  0.5881   \n",
      "2       103      0     12.20    1   False  0.132  0.2069  3.6939  0.6117   \n",
      "3       103      0     12.20    2   False  0.231  0.2195  3.2588  0.5904   \n",
      "4       103  19702     12.12    3   False   None     NaN     NaN     NaN   \n",
      "...     ...    ...       ...  ...     ...    ...     ...     ...     ...   \n",
      "71946    54  18603      9.83    2   False   None -0.0648  2.6204  0.4758   \n",
      "71947    54   8205      9.82    1   False   None  0.0134  2.4736  0.4804   \n",
      "71948    54   8205      9.82    3   False   None  0.0519  2.4502  0.4625   \n",
      "71949    54   8205      9.82    2   False   None  0.1353  2.1423  0.4737   \n",
      "71950    54   8205      9.82    0   False   None  0.1309  2.4773  0.4857   \n",
      "\n",
      "        m20_I  mprime_I  asym_H    cc_H     g_H   m20_H  mprime_H  t_lastmaj  \\\n",
      "0     -1.4073   -1.3047  0.1193  3.6158  0.5952 -1.9186   -1.5796    -2.6956   \n",
      "1     -1.5640   -1.1394  0.1433  3.8279  0.5921 -1.9774   -1.2196    -2.6956   \n",
      "2     -1.5015   -1.0887  0.1663  3.8399  0.5917 -1.8892   -1.2522    -2.6956   \n",
      "3     -1.5522   -1.3975  0.1482  3.8950  0.6085 -2.0038   -1.3152    -2.6956   \n",
      "4         NaN       NaN     NaN     NaN     NaN     NaN       NaN    -0.5016   \n",
      "...       ...       ...     ...     ...     ...     ...       ...        ...   \n",
      "71946 -1.2925   -0.3358 -0.1215  2.2644  0.4750 -1.4103   -0.5217    -1.0475   \n",
      "71947 -1.5007   -1.1829 -0.1366  2.4745  0.5023 -1.5417    0.2205    -0.3715   \n",
      "71948 -1.3560   -0.8130 -0.1186  2.5425  0.4749 -1.5294    0.2499    -0.3715   \n",
      "71949 -1.2310   -0.5579 -0.0662  2.2829  0.4540 -1.4985    0.2494    -0.3715   \n",
      "71950 -1.3748   -0.6035 -0.1294  2.4766  0.4684 -1.6014    0.2461    -0.3715   \n",
      "\n",
      "       t_lastmin  t_nextmaj  t_nextmin  \n",
      "0        -0.6481     4.4276    50.0000  \n",
      "1        -0.6481     4.4276    50.0000  \n",
      "2        -0.6481     4.4276    50.0000  \n",
      "3        -0.6481     4.4276    50.0000  \n",
      "4        -1.4423    50.0000    50.0000  \n",
      "...          ...        ...        ...  \n",
      "71946   -50.0000    10.5717    50.0000  \n",
      "71947    -0.5883     0.2776     0.6182  \n",
      "71948    -0.5883     0.2776     0.6182  \n",
      "71949    -0.5883     0.2776     0.6182  \n",
      "71950    -0.5883     0.2776     0.6182  \n",
      "\n",
      "[71951 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract only objects from snapshot 68 (z=2)\n",
    "merged_68 = catalog[catalog['snap'] == 68]\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fad80d5d-cfd4-4c62-9393-4021f59dcde8",
   "metadata": {},
   "source": [
    "Produção dos Samples de Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f846bf01-10a2-49e6-997b-18e20e83ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with objects used in RF and those excluded\n",
    "rf_objects = np.array([[row['subid'], row['merger']] for _, row in merged_68.iterrows()], dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0f56f0a-02c2-4f78-a1e2-039716f3332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique object IDs and their corresponding merger labels\n",
    "subid, indices = np.unique(rf_objects[:, 0], return_index=True)\n",
    "RF_labels = rf_objects[indices]\n",
    "\n",
    "shid_array = RF_labels[:, 0]\n",
    "merger_labels = RF_labels[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca51fd00-0c6c-4c56-9041-06f9cddcc424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copiando dados: 100%|███████████| 16/16 [00:00<00:00, 272.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Caminho do arquivo HDF5 de origem\n",
    "source_path = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\pristineFITS.hdf5\"\n",
    "\n",
    "# Diretório para salvar os dados copiados\n",
    "path = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\resized1\"\n",
    "subdirs = ['res_subdir_{:03d}'.format(x) for x in range(23)]\n",
    "\n",
    "# Criar os subdiretórios se não existirem\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(os.path.join(path, subdir), exist_ok=True)\n",
    "\n",
    "# Abrir o arquivo HDF5 de origem\n",
    "with h5py.File(source_path, \"r\") as source_file:\n",
    "    # Iterar por cada grupo de imagem no arquivo HDF5\n",
    "    for group_name in tqdm(source_file.keys(), desc=\"Copiando dados\"):\n",
    "        # Extrair o índice do subdiretório da parte numérica do nome do grupo\n",
    "        group_index = int(group_name.split(\"_\")[1])  # Assume que o nome do grupo é \"imagem_###\"\n",
    "\n",
    "        # Criar um novo arquivo HDF5 para cada grupo de imagem\n",
    "        group_path = os.path.join(path, subdirs[group_index], f\"{group_name}.hdf5\")\n",
    "        with h5py.File(group_path, \"w\") as target_file:\n",
    "            # Copiar os datasets para o novo arquivo\n",
    "            for dataset_name in source_file[group_name].keys():\n",
    "                target_file.create_dataset(dataset_name, data=source_file[group_name][dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70c55aef-06b3-4067-b406-f57928e4777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initialize lists to store image data\n",
      "list_of_mergers = []\n",
      "list_of_nonmergers = []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Carregando imagens: 100%|███████| 23/23 [00:00<00:00, 893.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Diretório base\n",
    "base_dir = r\"C:\\Users\\stefa\\OneDrive\\Documentos\\Natali 2\\Pristine\\resized1\"\n",
    "\n",
    "# Inicializar as listas de imagens\n",
    "list_of_mergers = []\n",
    "list_of_nonmergers = []\n",
    "\n",
    "# Print the initialization of the lists\n",
    "print(\"# Initialize lists to store image data\")\n",
    "print(\"list_of_mergers = []\")\n",
    "print(\"list_of_nonmergers = []\")\n",
    "\n",
    "# Iterar por cada subdiretório\n",
    "for subdir in tqdm(os.listdir(base_dir), desc=\"Carregando imagens\"):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Iterar por cada arquivo HDF5 no subdiretório\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith(\".hdf5\"):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                # Carregar o arquivo HDF5\n",
    "                with h5py.File(file_path, \"r\") as f:\n",
    "                    # Obter a imagem e o rótulo da fusão\n",
    "                    image_f814w = f[\"f814w\"][...]\n",
    "                    image_f160w = f[\"f160w\"][...]\n",
    "                    merger = bool(f[\"merger\"][...])\n",
    "\n",
    "                    # Criar um array com as duas imagens\n",
    "                    image_combined = np.stack((image_f814w, image_f160w), axis=0)\n",
    "\n",
    "                    # Adicionar à lista apropriada com base no rótulo de fusão\n",
    "                    if merger:\n",
    "                        list_of_mergers.append(image_combined)\n",
    "                    else:\n",
    "                        list_of_nonmergers.append(image_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68117b26-adec-4353-9d1e-1dd04949e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through objects and their merger labels\n",
    "for shid, merger in zip(shid_array, merger_labels):\n",
    "    for camnum in ['00', '01', '02', '03']:\n",
    "        filter_files = np.sort(np.asarray(glob.glob(os.path.join(path, 'res_sub*', '*sh' + str(shid) + 'cam' + camnum + '*SB00.npy'))))\n",
    "\n",
    "        # Check if there are exactly 4 files for each object\n",
    "        if len(filter_files) != 4:\n",
    "            continue\n",
    "\n",
    "        # Load image data for all 4 filters\n",
    "        tmp = np.zeros((4, 75, 75))\n",
    "        for i, file in enumerate(filter_files):\n",
    "            tmp[i, :, :] = np.load(file)\n",
    "\n",
    "        # Append image data to corresponding list based on merger label\n",
    "        if merger:\n",
    "            list_of_mergers.append(tmp)\n",
    "        else:\n",
    "            list_of_nonmergers.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ac660e5-94c0-4b29-b916-1e2df2bf48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack image data and create labels\n",
    "mergers = np.stack(list_of_mergers)\n",
    "notmergers = np.stack(list_of_nonmergers)\n",
    "mergers_y = np.ones(mergers.shape[0])\n",
    "notmergers_y = np.zeros(notmergers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97c10e41-1d83-41af-90e6-3cf43a195f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data and labels\n",
    "XX = np.vstack((mergers, notmergers))\n",
    "yy = np.concatenate((mergers_y, notmergers_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a35b1c9-8b14-4423-a26f-2f3b15cc5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data and labels\n",
    "np.save('SB00.npy', XX)\n",
    "np.save('SB00_y.npy', yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfa75035-9335-4280-991a-124e5011aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (XX) saved to 'SB00.npy' with shape: (16, 2, 75, 75)\n",
      "Labels (yy) saved to 'SB00_y.npy' with shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved files to get their sizes\n",
    "XX_loaded = np.load('SB00.npy')\n",
    "yy_loaded = np.load('SB00_y.npy')\n",
    "\n",
    "# Print information about the saved arrays\n",
    "print(f\"Data (XX) saved to 'SB00.npy' with shape: {XX_loaded.shape}\")\n",
    "print(f\"Labels (yy) saved to 'SB00_y.npy' with shape: {yy_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c85cbabf-1a29-45ae-b776-6806a9c5cb1e",
   "metadata": {},
   "source": [
    "Aprimoramento da extração dos dados merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8992fc44-9560-4768-b467-578a0f63558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved files to get their sizes\n",
    "XX_loaded = np.load('SB00.npy')\n",
    "yy_loaded = np.load('SB00_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7656375c-6265-4afd-9b0d-9a0afdcf2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_data_list = []  # Initialize an empty list to store the selected data\n",
    "for i in range(len(XX)):  # Loop through all 16 samples (assuming XX is your array)\n",
    "    xx_data_list.append([XX[i, 0], XX[i, 1]])  # Append a list containing data from channels 0 and 1 for each sample\n",
    "xx_data = np.stack(xx_data_list)  # Combine the lists into a NumPy array\n",
    "yy_data = yy  # Assign yy_data to the value of yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba7e8513-8820-4486-9bf1-36185053087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2, 75, 75)\n"
     ]
    }
   ],
   "source": [
    "print(XX_loaded.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6798898b-c60c-4209-b425-9ba4d8e8db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate augmented data by applying transformations\n",
    "for i in range(len(xx_data)):  # Corrected loop range\n",
    "    # Up-down flip\n",
    "    tmp = np.zeros((2, 75, 75))\n",
    "    tmp[0, :, :] = np.flipud(xx_data[i, 0])\n",
    "    tmp[1, :, :] = np.flipud(xx_data[i, 1])\n",
    "    list_ud.append(tmp)\n",
    "\n",
    "    # Left-right flip\n",
    "    tmp = np.zeros((2, 75, 75))\n",
    "    tmp[0, :, :] = np.fliplr(xx_data[i, 0])\n",
    "    tmp[1, :, :] = np.fliplr(xx_data[i, 1])\n",
    "    list_lr.append(tmp)\n",
    "\n",
    "    # 90 degrees rotation\n",
    "    tmp = np.zeros((2, 75, 75))\n",
    "    tmp[0, :, :] = np.rot90(xx_data[i, 0])\n",
    "    tmp[1, :, :] = np.rot90(xx_data[i, 1])\n",
    "    list_rot.append(tmp)\n",
    "\n",
    "    # 180 degrees rotation\n",
    "    tmp = np.zeros((2, 75, 75))\n",
    "    tmp[0, :, :] = np.rot90(np.rot90(xx_data[i, 0]))\n",
    "    tmp[1, :, :] = np.rot90(np.rot90(xx_data[i, 1]))\n",
    "    list_rot180.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "704e4354-d75b-4a00-8bac-7070e926a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "mergers_ud = np.stack(list_ud)\n",
    "mergers_lr = np.stack(list_lr)\n",
    "mergers_rot = np.stack(list_rot)\n",
    "mergers_rot180 = np.stack(list_rot180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "998d1b93-fc1e-4d89-88ea-6f01761e9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for the augmented data\n",
    "y_ud = np.ones(mergers_ud.shape[0])\n",
    "y_lr = np.ones(mergers_lr.shape[0])\n",
    "y_rot = np.ones(mergers_rot.shape[0])\n",
    "y_rot180 = np.ones(mergers_rot180.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f9b7fd0-c8d8-4fdd-a7bc-713c2da81261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original and augmented data\n",
    "X_augmented = np.vstack((xx_data[:1624], mergers_ud, mergers_lr, mergers_rot, mergers_rot180, xx_data[1624:]))\n",
    "y_augmented = np.concatenate((yy_data[:1624], y_ud, y_lr, y_rot, y_rot180, yy_data[1624:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e904ad4-9546-44fc-8dc5-c8c61df5e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the augmented data\n",
    "np.save('SB00_augmented.npy', X_augmented)\n",
    "np.save('SB00_augmented_y.npy', y_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bd472da-202f-45c0-9c20-36108ecea17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "# Print the lengths of the augmented datasets\n",
    "print(len(X_augmented))\n",
    "print(len(y_augmented))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
